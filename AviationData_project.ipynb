{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Overview**\n",
        "\n",
        "This dataset consists of aviation accident survey data, which includes information on whether the aircraft was destroyed, the type of injuries sustained by individuals, the location of the accidents along with the year and month, the type of engine involved, weather conditions, the purpose of the flight, and other relevant details."
      ],
      "metadata": {
        "id": "8HjACSyYWGdh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Business Problem**\n",
        "\n",
        "This analysis aims to identify patterns and trends in aviation accidents to enhance safety measures. By understanding the relationship between weather conditions, engine types, injury severity, and flight purpose, we can develop insights to prevent future accidents. The findings will support data-driven decision-making in aviation safety policies and operational practices. Ultimately, this research seeks to improve overall flight safety and reduce accident-related risks"
      ],
      "metadata": {
        "id": "MAAPRYuoXTYV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Understanding**\n",
        "\n",
        "In this data analysis, the first step involves importing the necessary libraries and loading the dataset to begin the analysis. Next, I will handle any missing values to ensure the data is complete and reliable. Following this, I will transform the data to enhance its interpretability, such as grouping related categories into broader groups for better clarity. The data will then be explored through various visualizations to uncover relationships and patterns between key variables, such as weather conditions, injury severity, and flight purposes. Finally, I will summarize the findings and provide conclusions that offer insights into aviation safety and accident prevention."
      ],
      "metadata": {
        "id": "NzYSaHFkXcpv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATA AND LIBRARY IMPORTATION**"
      ],
      "metadata": {
        "id": "gvhv6I6XYeJJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VhgnxvwSE7At"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.cm as cm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading dataset\n",
        "df = pd.read_csv('AviationData.csv', encoding='latin-1')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "49fXfIb3GBaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATA** **UNDERSTANDING**\n",
        "\n"
      ],
      "metadata": {
        "id": "cpobTGLvwKfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# understanding basic information of the dataset\n",
        "df.info()"
      ],
      "metadata": {
        "id": "ilonybz1GZ9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a copy of my original data so as not to bring any modification\n",
        "df1 = df.copy()\n"
      ],
      "metadata": {
        "id": "fIUvkkXJpXS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HANDLING** **MISSING** **VALUES**\n"
      ],
      "metadata": {
        "id": "8c4KtbWAk3LZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping columns that have a lot of missing values\n",
        "df1.drop(columns=['Latitude'], inplace=True)\n",
        "df1.drop(columns=['Longitude'],inplace=True)\n",
        "df1.drop(columns=['Airport.Code'],inplace=True)\n",
        "df1.drop(columns=['Airport.Name'],inplace=True)\n",
        "df1.drop(columns=['Aircraft.Category'],inplace=True)\n",
        "df1.drop(columns=['FAR.Description'],inplace=True)\n",
        "df1.drop(columns=['Schedule'],inplace=True)\n",
        "df1.drop(columns=['Air.carrier'],inplace=True)"
      ],
      "metadata": {
        "id": "WwEbFhnMGfQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.info()"
      ],
      "metadata": {
        "id": "Nn126o7Mlp7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the number of missing value\n",
        "df1.isnull().sum()"
      ],
      "metadata": {
        "id": "HojmMAmnmk_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATA** **CLEANING**"
      ],
      "metadata": {
        "id": "9lVor5JNF1um"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# further columns removal\n",
        "columns_name = ['Publication.Date','Broad.phase.of.flight','Engine.Type']\n",
        "df1.drop(columns=columns_name,inplace=True)"
      ],
      "metadata": {
        "id": "KrelW99bt4r1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.info()"
      ],
      "metadata": {
        "id": "1gedT-Bhw8mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a subset with only numerical columns\n",
        "df1_num = df1.select_dtypes(include=['number'])"
      ],
      "metadata": {
        "id": "uNTUXUGYxAH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1_num.corr()"
      ],
      "metadata": {
        "id": "BsJo_macyIhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ploting the correlation between the different columns\n",
        "sns.pairplot(df1_num)"
      ],
      "metadata": {
        "id": "9qMqADfNyVF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this plots i can understand that the correlation betweeen the columns is poor,so the correlation can not be used to handle missing values\n"
      ],
      "metadata": {
        "id": "H8XYUDkMzS9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# in order to handle the missing values, the mean,median and mode for each column is computed so as to understand the distribution of the data\n",
        "\n",
        "mean1=df1_num['Total.Fatal.Injuries'].mean()\n",
        "median1=df1_num['Total.Fatal.Injuries'].median()\n",
        "mode1=df1_num['Total.Fatal.Injuries'].mode()[0]\n",
        "print(f\"Mean: {mean1}, Median: {median1}, Mode: {mode1}\")"
      ],
      "metadata": {
        "id": "IXz9v7Hn2007"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean2=df1_num['Total.Serious.Injuries'].mean()\n",
        "median2=df1_num['Total.Serious.Injuries'].median()\n",
        "mode2=df1_num['Total.Serious.Injuries'].mode()[0]\n",
        "print(f\"Mean: {mean2}, Median: {median2}, Mode: {mode2}\")"
      ],
      "metadata": {
        "id": "lgWJ5LIX6HSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean3=df1_num['Total.Minor.Injuries'].mean()\n",
        "median3=df1_num['Total.Minor.Injuries'].median()\n",
        "mode3=df1_num['Total.Minor.Injuries'].mode()[0]\n",
        "print(f\"Mean: {mean3}, Median: {median3}, Mode: {mode3}\")"
      ],
      "metadata": {
        "id": "ewdqo0rJ7fBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean4=df1_num['Total.Uninjured'].mean()\n",
        "median4=df1_num['Total.Uninjured'].median()\n",
        "mode4=df1_num['Total.Uninjured'].mode()[0]\n",
        "print(f\"Mean: {mean4}, Median: {median4}, Mode: {mode4}\")"
      ],
      "metadata": {
        "id": "Ln87oyMb7yY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1_num['Total.Fatal.Injuries'].fillna(median1, inplace=True)\n",
        "df1_num['Total.Serious.Injuries'].fillna(median2, inplace=True)\n",
        "df1_num['Total.Minor.Injuries'].fillna(median3, inplace=True)\n",
        "df1_num['Total.Uninjured'].fillna(median4, inplace=True)"
      ],
      "metadata": {
        "id": "gnZeMDj19UZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1_num.isnull().sum()"
      ],
      "metadata": {
        "id": "9Tc5U9q8-ACC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I am returning back to the data frame the numerical columns,where the missing value has just been handled\n",
        "\n",
        "columns_to_replace = ['Total.Fatal.Injuries', 'Total.Serious.Injuries','Total.Minor.Injuries','Total.Uninjured']\n",
        "df1[columns_to_replace] = df1_num[columns_to_replace]\n"
      ],
      "metadata": {
        "id": "WApmo96m-hdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.isnull().sum()"
      ],
      "metadata": {
        "id": "1veqPsAWdfQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.info()"
      ],
      "metadata": {
        "id": "Rwl3dk0dcfQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Am checking missing value in the columns if they share the same row\n",
        "\n",
        "num_nulls = df1.isnull().sum(axis=1)\n",
        "rows_with_nulls = df1[num_nulls == 9].index\n",
        "rows_with_nulls\n",
        "df1= df1.drop(index=rows_with_nulls )\n",
        "df1.isnull().sum()\n"
      ],
      "metadata": {
        "id": "OpOKAbDacn5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATA** **HANDLING**"
      ],
      "metadata": {
        "id": "30SACMfTtqc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# i want to convert the Event.Date to seperate columns year,month,day. So am doing this to compare it year wise,month wise and day wise\n",
        "\n",
        "df1['Event.Date'] = pd.to_datetime(df['Event.Date'])\n",
        "df1['Event.Year'] = df1['Event.Date'].dt.year\n",
        "df1['Event.Month'] = df1['Event.Date'].dt.month\n",
        "df1['Event.Day'] = df1['Event.Date'].dt.day"
      ],
      "metadata": {
        "id": "JeCgkIaSl9vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I want to change the Injury.Severity column. When the value is fetal,the number of people injured is written with it so am going to seperate them.\n",
        "\n",
        "df1['num_injured'] = df1['Injury.Severity'].str.extract(r'\\((\\d+)\\)').astype(float)\n",
        "df1['Injury.Severity'] = df1['Injury.Severity'].str.replace(r'\\(\\d+\\)', '', regex=True).str.strip()\n",
        "df1['Injury.Severity'].unique()"
      ],
      "metadata": {
        "id": "jhkRuVEprtml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# So i decided to change the 'Serious' injuries to Fatal while the 'Minor' and 'Incident' to NOn-Fetal. Incident was considered as minor because the corrisponding value in Aircraft.damage is minor.\n",
        "# The purpuse of this is to reduce the categories.\n",
        "\n",
        "df1['Injury.Severity'] = df1['Injury.Severity'].replace({\n",
        "    'Serious': 'Fatal',\n",
        "    'Incident': 'Non-Fatal',\n",
        "    'Minor': 'Non-Fatal',\n",
        "    'Unavailable': np.nan\n",
        "})\n",
        "df1['Injury.Severity'].unique()"
      ],
      "metadata": {
        "id": "0sFzXy36yN_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['Aircraft.damage'].unique()"
      ],
      "metadata": {
        "id": "29PwzKR_w7ky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I am going to consider the Substaintial and Minor as Non destroyed,Unknown is going to be considered as nan.\n",
        "\n",
        "df1[\"Aircraft.damage\"] = df1[\"Aircraft.damage\"].replace({\n",
        "    'Minor': 'Non-Destroyed',\n",
        "    'Substantial': 'Non-Destroyed',\n",
        "    'Unknown': np.nan\n",
        "})\n",
        "df1['Aircraft.damage'].unique()"
      ],
      "metadata": {
        "id": "C549QzogxV6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['Purpose.of.flight'].unique()"
      ],
      "metadata": {
        "id": "jGhQRk-Uy1TP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Since Purpose of has many categorical values, i am going to arrenge them in to 7 categories\n",
        "category_mapping = {\n",
        "    'Personal': 'Personal/Business',\n",
        "    'Business': 'Personal/Business',\n",
        "    'Executive/corporate': 'Personal/Business',\n",
        "    'Other Work Use': 'Personal/Business',\n",
        "    'Positioning': 'Ferry/Positioning',\n",
        "    'Instructional': 'Flight Training/Testing',\n",
        "    'Flight Test': 'Flight Training/Testing',\n",
        "    'Unknown': np.nan,\n",
        "    'Ferry': 'Ferry/Positioning',\n",
        "    'Aerial Observation': 'Aerial Work',\n",
        "    'Aerial Application': 'Aerial Work',\n",
        "    'Public Aircraft': 'Public Aircraft',\n",
        "    'Skydiving': 'Recreational/Sport',\n",
        "    'Air Race/show': 'Recreational/Sport',\n",
        "    'Air Race show': 'Recreational/Sport',\n",
        "    'Air Drop': 'Aerial Work',\n",
        "    'Public Aircraft - Federal': 'Public Aircraft',\n",
        "    'Glider Tow': 'Aerial Work',\n",
        "    'Public Aircraft - Local': 'Public Aircraft',\n",
        "    'External Load': 'Aerial Work',\n",
        "    'Public Aircraft - State': 'Public Aircraft',\n",
        "    'Banner Tow': 'Aerial Work',\n",
        "    'Firefighting': 'Aerial Work',\n",
        "    'ASHO': 'Recreational/Sport',\n",
        "    'PUBS': 'Public Aircraft',\n",
        "    'PUBL': 'Public Aircraft'\n",
        "}\n",
        "df1['Purpose.of.flight'] = df1['Purpose.of.flight'].replace(category_mapping)\n",
        "df1['Purpose.of.flight'].unique()"
      ],
      "metadata": {
        "id": "zN8v8rPCzkjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['Weather.Condition'].unique()"
      ],
      "metadata": {
        "id": "w0tfV5d65Efm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Am changing the UNK value in nan in Weather Condition column\n",
        "\n",
        "df1['Weather.Condition'] = df1['Weather.Condition'].replace({\n",
        "    'Unk': np.nan,\n",
        "    'UNK': np.nan ,\n",
        "    'Unavailable': np.nan\n",
        "})\n",
        "df1['Weather.Condition'].unique()"
      ],
      "metadata": {
        "id": "-lcCXjDR9vah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The Report.status column is removed because it has entry that has long sentances.\n",
        "\n",
        "df1.drop(['Report.Status'],axis=1 ,inplace=True)"
      ],
      "metadata": {
        "id": "-vpeweSN_Yt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.info()"
      ],
      "metadata": {
        "id": "ac9-7XhCAoJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# i am filling all the nan values with UNK\n",
        "df1.fillna(\"UNK\", inplace=True)"
      ],
      "metadata": {
        "id": "QRBnSPbzG8zK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.drop(['num_injured'],axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "WqNttUdtBQNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The value for location is seperated into city and state\n",
        "\n",
        "df1['City'] = df['Location'].str.split(',').str[0]\n",
        "df1['State'] = df['Location'].str.split(',').str[1]"
      ],
      "metadata": {
        "id": "szNikZIrCxly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATA VISUALIZATION**"
      ],
      "metadata": {
        "id": "vrHUB8a9lazE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#In this code i am trying to understand what is the weather like during accidents\n",
        "weather_condition_counts = df1['Weather.Condition'].value_counts()\n",
        "sns.barplot(\n",
        "    x=weather_condition_counts.values,\n",
        "    y=weather_condition_counts.index,\n",
        "    palette=\"coolwarm\",\n",
        "    hue=weather_condition_counts.index,\n",
        "    dodge=False,\n",
        "    legend=False\n",
        ")\n",
        "plt.xlabel('Count')\n",
        "plt.ylabel('Weather Condition')\n",
        "plt.title('Count of Weather Condition Type During Accident')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "swYaDAEqrqkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "conclusion:i observed that most of the accident occur when the weather condition is VMC meaning the visibility is good."
      ],
      "metadata": {
        "id": "DNmlw8lSDc87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# in this plot i will count the type of weather condition for each type of injury so as to understand what kind of weather prevails for different degree of injury\n",
        "\n",
        "injury_columns = ['Total.Fatal.Injuries', 'Total.Serious.Injuries', 'Total.Minor.Injuries', 'Total.Uninjured']\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "for i, column in enumerate(injury_columns):\n",
        "    injury_counts_by_weather = df1.groupby('Weather.Condition')[column].count()\n",
        "    sns.barplot(\n",
        "        x=injury_counts_by_weather.index,\n",
        "        y=injury_counts_by_weather.values,\n",
        "        ax=axes[i // 2, i % 2],\n",
        "        palette=\"coolwarm\",\n",
        "        hue=injury_counts_by_weather.index,\n",
        "        legend=False\n",
        "    )\n",
        "    axes[i // 2, i % 2].set_title(f'Weather Condition Count for {column}')\n",
        "    axes[i // 2, i % 2].set_xlabel('Weather Condition')\n",
        "    axes[i // 2, i % 2].set_ylabel('Count')\n",
        "    axes[i // 2, i % 2].tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9dWX15Rbuprq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**conclusion**: it can be seen that for all the injury the weather condition is VMC"
      ],
      "metadata": {
        "id": "MDqKuwzIH797"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1['Weather.Condition'].unique()"
      ],
      "metadata": {
        "id": "UEuURtLjFxol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#i want to see the relationship of engine type with the injury type, so as to understand which engine type result in major\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "for i, column in enumerate(injury_columns):\n",
        "    injury_counts_by_engines = df1.groupby('Number.of.Engines')[column].count()\n",
        "    sns.barplot(\n",
        "        x=injury_counts_by_engines.values,\n",
        "        y=injury_counts_by_engines.index,\n",
        "        ax=axes[i // 2, i % 2],\n",
        "        palette=\"coolwarm\",\n",
        "        hue=injury_counts_by_engines.index,\n",
        "        legend=False\n",
        "    )\n",
        "    axes[i // 2, i % 2].set_title(f'Injury Count for {column} by Number of Engines')\n",
        "    axes[i // 2, i % 2].set_xlabel('Count')\n",
        "    axes[i // 2, i % 2].set_ylabel('Number of Engines')\n",
        "    axes[i // 2, i % 2].tick_params(axis='y', rotation=0)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8ZTPHXKNu5iD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**conclusion**:engine 1 has the highest number of accidents for the different injuries."
      ],
      "metadata": {
        "id": "zy1ZkLkEZRDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#i want to see the relation between type ofinjury and the purpose of flight, to see in what kind of purposes the accident is fatal and in which is just minor\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "for i, column in enumerate(injury_columns):\n",
        "    injury_counts_by_purpose = df1.groupby('Purpose.of.flight')[column].count()\n",
        "    sns.barplot(\n",
        "        x=injury_counts_by_purpose.values,\n",
        "        y=injury_counts_by_purpose.index,\n",
        "        ax=axes[i // 2, i % 2],\n",
        "        palette=\"coolwarm\",\n",
        "        hue=injury_counts_by_purpose.index,\n",
        "        legend=False\n",
        "    )\n",
        "    axes[i // 2, i % 2].set_title(f'Injury Count for {column} by Purpose of Flight')\n",
        "    axes[i // 2, i % 2].set_xlabel('Count')\n",
        "    axes[i // 2, i % 2].set_ylabel('Purpose of Flight')\n",
        "    axes[i // 2, i % 2].tick_params(axis='y', rotation=0)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zwIVCBQk3Mgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**conclusion**: most of the injury occur for personal or business. substatial injuries also occur for flight training or testing purpose."
      ],
      "metadata": {
        "id": "WF5QdU-NMDRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#I want to see the relation between the injury type and the degree of damage of the aircraft, so as to see if there is a relation between fatal injury and destroyed aircraft.\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "for i, column in enumerate(injury_columns):\n",
        "    injury_counts_by_damage = df1.groupby('Aircraft.damage')[column].count()\n",
        "    sns.barplot(\n",
        "        x=injury_counts_by_damage.values,\n",
        "        y=injury_counts_by_damage.index,\n",
        "        ax=axes[i // 2, i % 2],\n",
        "        palette=\"coolwarm\",\n",
        "        hue=injury_counts_by_damage.index,\n",
        "        dodge=False,\n",
        "        legend=False\n",
        "    )\n",
        "    axes[i // 2, i % 2].set_title(f'Injury Count for {column} by Aircraft Damage')\n",
        "    axes[i // 2, i % 2].set_xlabel('Count')\n",
        "    axes[i // 2, i % 2].set_ylabel('Aircraft Damage')\n",
        "    axes[i // 2, i % 2].tick_params(axis='y', rotation=0)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KvEM4ck05H2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**conclusion**: most of the aircraft were not destroyed in relation to the different injury that occured."
      ],
      "metadata": {
        "id": "ZMMe63C9NTmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# i want to see the relationship between top 10 country and type of injury, so as to understand which country has highest number of different type of injury\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "for i, column in enumerate(injury_columns):\n",
        "    injury_counts_by_country = df1.groupby('Country')[column].count()\n",
        "    top_countries = injury_counts_by_country.nlargest(10)\n",
        "    sns.barplot(\n",
        "        x=top_countries.values,\n",
        "        y=top_countries.index,\n",
        "        ax=axes[i // 2, i % 2],\n",
        "        palette=\"coolwarm\",\n",
        "        hue=top_countries.index,\n",
        "        dodge=False,\n",
        "        legend=False\n",
        "    )\n",
        "    axes[i // 2, i % 2].set_title(f'Injury Count for {column} by Country')\n",
        "    axes[i // 2, i % 2].set_xlabel('Count')\n",
        "    axes[i // 2, i % 2].set_ylabel('Country')\n",
        "    axes[i // 2, i % 2].tick_params(axis='y', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ku1B4Bjx5ixh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**conclusion**: it can be seen that USA has the highest count  in number of accidents for different injury types."
      ],
      "metadata": {
        "id": "9TaJa9nCPIsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# i want to see the number of accidents for different states in the USA since the country has the highest accidents\n",
        "usa_accidents = df1[df1['Country'] == 'United States']\n",
        "accidents_by_state = usa_accidents.groupby('Location').size().nlargest(10)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=accidents_by_state.values, y=accidents_by_state.index, palette=\"coolwarm\", hue=accidents_by_state.index)\n",
        "\n",
        "plt.xlabel('Number of Accidents')\n",
        "plt.ylabel('State')\n",
        "plt.title('Top 10 States with the Highest Number of Accidents (United States)')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F9eZLCURUE-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**conclusion**: Anchorage state has the highest accidents"
      ],
      "metadata": {
        "id": "U_ZjremQUx6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# i want to see the number of accident per year so as to know which years have high value\n",
        "accidents_per_year = df1.groupby('Event.Year').size()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(x=accidents_per_year.index, y=accidents_per_year.values, marker='o', color='b')\n",
        "\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Number of Accidents')\n",
        "plt.title('Number of Accidents per Year')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YhoxlvvZ6C-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**conclusion**: there are a lot of accidents after 1980"
      ],
      "metadata": {
        "id": "PwxecgXzRI1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#To visualize the number of accidents by month from the year 1980 onward, to know which month have high accidents\n",
        "df_filtered = df1[df1['Event.Year'] >= 1980]\n",
        "accidents_by_month = df_filtered.groupby(['Event.Year', 'Event.Month']).size().unstack(fill_value=0)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(accidents_by_month, cmap='YlGnBu', annot=True, fmt='d', cbar_kws={'label': 'Number of Accidents'}, linewidths=0.5)\n",
        "\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Year')\n",
        "plt.title('Heatmap of Number of Accidents by Month (From 1980 Onward)')\n",
        "plt.xticks(ticks=range(12), labels=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'], rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RNVZ4ek5R37i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**conclusion**: summer months show more accidents form 1980 onward. It is especially high for late years than recent ones."
      ],
      "metadata": {
        "id": "wrCwl84NSr16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# i want to see the number of accidents per company maker so as to know which company is not doing a good job\n",
        "accidents_by_make = df1.groupby('Make').size().nlargest(10)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=accidents_by_make.values, y=accidents_by_make.index, palette=\"coolwarm\", hue=accidents_by_make.index)\n",
        "\n",
        "plt.xlabel('Number of Accidents')\n",
        "plt.ylabel('Company Maker')\n",
        "plt.title('Top 10 Company Makers with the Highest Number of Accidents')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B1Ns4p-MZ7iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**conclusion**: Cessna has the highest record of accidents followed by Piper."
      ],
      "metadata": {
        "id": "avETK5wBamq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#i want to see the relationship between the number of accidents for Cessna and Piper, and how this varies over the years from 1980 onwards\n",
        "filtered_data = df1[(df1['Make'].isin(['Cessna', 'Piper'])) & (df1['Event.Year'] >= 1980)]\n",
        "\n",
        "accidents_by_year = filtered_data.groupby(['Event.Year', 'Make']).size().unstack().fillna(0)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "accidents_by_year.plot(kind='line', marker='o', color=sns.color_palette(\"coolwarm\", 2))\n",
        "\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Number of Accidents')\n",
        "plt.title('Number of Accidents for Cessna and Piper Over the Years (1980 and Beyond)')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SUe2TXEBbNVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**conclusion**: it can be seen that the accidents were slowly decreasing from 1980 onward, but around 2016 a suddent increase occured which slowly decreased till  2022"
      ],
      "metadata": {
        "id": "cBP1M8l7buly"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion**\n",
        "\n",
        "Weather Condition: VMC (Visual Meteorological Conditions) is the most common weather condition for accidents across all injury types.\n",
        "\n",
        "Engine Type: Single-engine aircraft (1 engine) are involved in the majority of accidents.\n",
        "\n",
        "Purpose of Flight: Most accidents occur during personal or business flights.\n",
        "\n",
        "Aircraft Damage: The majority of accidents do not result in severe aircraft destruction.\n",
        "\n",
        "Geographic Location: The USA has the highest number of recorded accidents, with Anchorage having the highest accident rate among states.\n",
        "\n",
        "Trends Over Time: A significant number of accidents have occurred since 1980, with a descending trend in recent years.\n",
        "\n",
        "Seasonal Pattern: The highest number of accidents occur during the summer months.\n",
        "\n",
        "Aircraft Make: Cessna is the maker with the highest number of accidents, followed by Piper.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RpXiCGDgcYM-"
      }
    }
  ]
}